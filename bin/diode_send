#!/usr/bin/env python3
"""
Send files through unidirectional serial device
"""

import argparse
import hashlib
import json
import logging
import math
import os
import socket
import time
import sys

from logging import handlers

DIODE_LOGGER = logging.getLogger('DIODE')
DIODE_LOGGER.setLevel(logging.INFO)
SYSLOG_FORMATTER = logging.Formatter('%(name)s %(levelname)s: %(message)s')
STDERR_FORMATTER = logging.Formatter('%(asctime)s %(levelname)s: %(message)s')
SYSLOG_HANDLER = handlers.SysLogHandler(address='/dev/log')
SYSLOG_HANDLER.setFormatter(SYSLOG_FORMATTER)
STDERR_HANDLER = logging.StreamHandler(sys.stderr)
STDERR_HANDLER.setLevel(logging.DEBUG)
STDERR_HANDLER.setFormatter(STDERR_FORMATTER)
DIODE_LOGGER.addHandler(SYSLOG_HANDLER)
DIODE_LOGGER.addHandler(STDERR_HANDLER)

PARSER = argparse.ArgumentParser(description='Serial device options')
PARSER.add_argument('--target-subnet', type=str, nargs='?', default="10.125.125.255",
                    help='Target subnet broadcast IP')
PARSER.add_argument('--target-port', type=int, nargs='?', default=5005,
                    help='Target port')
PARSER.add_argument('--directory', type=str, nargs='?', required=True,
                    help='directory from which to send files')
ARGS = PARSER.parse_args()


CHUNK_SIZE = 640
TARGET_IP = ARGS.target_subnet
TARGET_PORT = int(ARGS.target_port)
SOURCE_DIR = ARGS.directory
DELAY_NEXT_CHUNK = 4000
BATCH_SIZE = 1000
RESEND_PACKET = 3
SCAN_INTERVAL = 1
STABILITY_CHECK_DELAY = 1

PKG_TYPE_START = 0
PKG_TYPE_DATA = 1
PKG_TYPE_END = 2

sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
sock.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1)

def busy_wait_sleep(cycles: int = DELAY_NEXT_CHUNK):
    """
    time.sleep() is too slow (on OpenBSD). Looping through
    a range can introduce "arbitrarily" short delays. Can be
    replaced by any other function that can introduce delays in
    the range of microseconds.
    """
    for n in range(0, cycles):
        i = n

def get_chunks(filepath: str, batch):
    """
    Read file chunks
    """
    with open(filepath, 'rb') as f:
        f.seek(batch*CHUNK_SIZE)
        for _ in range(BATCH_SIZE):
            data = f.read(CHUNK_SIZE)
            if not data:
                break  # End of file
            yield data

def send_start_paket(filepath: str, rel_path: str, rel_path_hash: str) -> None:
    """
    Send first paket with meta data
    """
    DIODE_LOGGER.info("Sending file: %s", rel_path)
    filesize = os.path.getsize(filepath)
    start_packet = json.dumps({
        'p': rel_path,
        's': filesize,
        't': PKG_TYPE_START,
        'h': rel_path_hash
    }).encode()
    for n in range(0, RESEND_PACKET):  # pylint: disable=unused-variable
        sock.sendto(start_packet, (TARGET_IP, TARGET_PORT))
        busy_wait_sleep(DELAY_NEXT_CHUNK)

def send_end_paket(filepath: str, rel_path: str, count: int) -> None:
    """
    Send last paket with final count
    """
    end_packet = json.dumps({"p":rel_path, 't': PKG_TYPE_END, 'c': count}).encode()
    for n in range(0, RESEND_PACKET):  # pylint: disable=unused-variable
        sock.sendto(end_packet, (TARGET_IP, TARGET_PORT))
        busy_wait_sleep(DELAY_NEXT_CHUNK)
    os.remove(filepath)
    DIODE_LOGGER.info("Finished sending file: %s", rel_path)

def send_data_paket(rel_path_hash: str, chunk: bytes, count: int) -> None:
    """
    Send data paket
    """
    hash_digest = hashlib.md5(chunk).hexdigest()
    packet = {
        'c': count,
        'p': rel_path_hash,
        'h': hash_digest,
        'd': chunk.hex(),
        't': PKG_TYPE_DATA,
    }
    data = json.dumps(packet).encode()
    sock.sendto(data, (TARGET_IP, TARGET_PORT))
    busy_wait_sleep(DELAY_NEXT_CHUNK)

def calculate_number_of_batches(filepath):
    """
    Calculate the number of batches. We want to send BATCH_SIZE packets
    in one batch.
    """
    filesize = os.path.getsize(filepath)
    return math.ceil(filesize/CHUNK_SIZE/BATCH_SIZE)

def send_file_chunks(filepath: str, rel_path: str) -> None:
    """
    Send a file chunk via UDP along with path and hash

    :param filepath: full path to file
    :param rel_path: relative path to file in relation to watched dir
    """
    rel_path_hash = hashlib.md5(rel_path.encode("utf-8")).hexdigest()
    num_batches = calculate_number_of_batches(filepath)
    send_start_paket(filepath, rel_path, rel_path_hash)
    count = 0
    batch_start_count = 0
    for batch in range(0, num_batches):
        batch_start_count = count
        for resend in range(0, RESEND_PACKET):
            for chunk in get_chunks(filepath, batch):
                send_data_paket(rel_path_hash, chunk, count)
                count += 1
            if resend < RESEND_PACKET - 1:
                count = batch_start_count
    send_end_paket(filepath, rel_path, count)

def is_file_stable(filepath: str, delay: int = STABILITY_CHECK_DELAY) -> bool:
    """Check if file size is stable after waiting for delay."""
    try:
        initial_size = os.path.getsize(filepath)
        time.sleep(delay)
        return os.path.getsize(filepath) == initial_size
    except FileNotFoundError:
        return False

def scan_directory() -> None:
    """
    Watch directory for new files. Send new files via UDP.
    """
    for root, _, files in os.walk(SOURCE_DIR):
        for file in files:
            full_path = os.path.join(root, file)
            rel_path = os.path.relpath(full_path, SOURCE_DIR)

            if is_file_stable(full_path):
                send_file_chunks(full_path, rel_path)

if __name__ == "__main__":
    os.makedirs(SOURCE_DIR, exist_ok=True)
    DIODE_LOGGER.info("Watching for new files in: %s", SOURCE_DIR)
    try:
        while True:
            scan_directory()
            time.sleep(SCAN_INTERVAL)
    except KeyboardInterrupt:
        DIODE_LOGGER.info("Stopped watching")
